# The setup section defines options related to setting pu test cases or suites
[setup]

# whether to copy the executable to the work directory
copy_executable = False

# Options related to downloading files
[download]

# the base url for the server from which meshes, initial conditions, and other
# data sets can be downloaded
server_base_url = https://web.lcrc.anl.gov/public/e3sm/polaris

# whether to download files during setup that have not been cached locally
download = True

# whether to check the size of files that have been downloaded to make sure
# they are the right size
check_size = False

# whether to verify SSL certificates for HTTPS requests
verify = True


# The parallel section describes options related to running tasks in parallel
[parallel]

# the program to use for graph partitioning
partition_executable = gpmetis

# the number of cores a user can use on a login node
login_cores = 4


# The io section describes options related to file i/o
[io]

# the NetCDF file format: NETCDF4, NETCDF4_CLASSIC, NETCDF3_64BIT, or
# NETCDF3_CLASSIC, NETCDF3_64BIT_DATA
format = NETCDF3_64BIT_DATA

# the NetCDF output engine: netcdf4, h5netcdf or scipy
engine = netcdf4


# Config options related to creating a job script
[job]

# the name of the parallel job
job_name = <<<default>>>

# wall-clock time
wall_time = 1:00:00

# The job partition to use, by default, taken from the first partition (if any)
# provided for the machine by mache
partition = <<<default>>>

# The job quality of service (QOS) to use, by default, taken from the first
# qos (if any) provided for the machine by mache
qos = <<<default>>>

# The job constraint to use, by default, taken from the first constraint (if
# any) provided for the  machine by mache
constraint = <<<default>>>

# The job queue to use, by default, taken from the first queue (if any)
# provided for the machine by mache
queue = <<<default>>>
